{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b08c0dc-eb15-4b1d-b3b0-c87a14d4576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from statsmodels.stats.anova import AnovaRM \n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import pingouin as pg\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9033e91a-a1f4-46c6-9a9a-1f0f1acc25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vn = ['fusiform-rh', 'fusiform-lh', 'lingual-lh', 'lingual-rh', 'cuneus-rh','cuneus-lh', 'lateraloccipital-rh', 'lateraloccipital-lh']\n",
    "\n",
    "methods = ['generalized_partial_directed_coherence', 'direct_directed_transfer_function', 'pairwise_spectral_granger_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6468600-88f5-4467-8a47-05fd5cc4d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assembling variance dictionaries\n",
    "\n",
    "inter_variance_dict = {}\n",
    "intra_variance_dict = {}\n",
    "\n",
    "intra_upper_outlier_dict = {}\n",
    "intra_lower_outlier_dict = {}\n",
    "\n",
    "inter_upper_outlier_dict = {}\n",
    "inter_lower_outlier_dict = {}\n",
    "\n",
    "for method in methods: \n",
    "    subject_files = glob.glob(f'/work/srishyla/{method}/*_EC.nc')\n",
    "\n",
    "    #intra\n",
    "    mean_per_subject = []\n",
    "    for file in subject_files:\n",
    "        xarray = xr.open_dataarray(file)\n",
    "        std_mean_list = []\n",
    "        for sample in range(0,100):\n",
    "            std = xarray.sel(bootstrap_samples=sample, region1=vn, region2=vn).values.std()\n",
    "            mean = xarray.sel(bootstrap_samples=sample, region1=vn, region2=vn).values.mean()\n",
    "            std_mean_list.append(std/mean)\n",
    "        mean_per_subject.append(np.mean(std_mean_list))\n",
    "    intra_variance_dict[method] = mean_per_subject\n",
    "\n",
    "    #outliers - INTRA\n",
    "    \n",
    "    q1 = np.percentile(intra_variance_dict[method], 25, method='midpoint')\n",
    "    q3 = np.percentile(intra_variance_dict[method], 75, method='midpoint')\n",
    "    iqr = q3 - q1\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper_array = np.where(intra_variance_dict[method] >= upper)[0]\n",
    "    lower_array = np.where(intra_variance_dict[method] <= lower)[0]\n",
    "    intra_upper_outlier_dict[method] = upper_array\n",
    "    intra_lower_outlier_dict[method] = lower_array\n",
    "    \n",
    "    #inter\n",
    "    all_bootstraps = []  #list of 11200 arrays\n",
    "    for file in subject_files:\n",
    "        xarray = xr.open_dataarray(file)\n",
    "        for sample in range(0,100):\n",
    "            bootstrap = xarray.sel(bootstrap_samples=sample, region1=vn, region2=vn).values\n",
    "            all_bootstraps.append(bootstrap)\n",
    "    \n",
    "    random_bootstraps = []\n",
    "    for i in range(0,112):\n",
    "        index = np.random.choice(range(0,11200),100)\n",
    "        sample = np.array(all_bootstraps)[index,:]\n",
    "        random_bootstraps.append(sample)\n",
    "\n",
    "    mean_per_bootstrap = []\n",
    "    for sample in random_bootstraps:\n",
    "        std_mean_list = []\n",
    "        for i in range(0,100):\n",
    "            std = sample[i].std()\n",
    "            mean = sample[i].mean()\n",
    "            std_mean_list.append(std/mean)\n",
    "    \n",
    "        mean_per_bootstrap.append(np.mean(std_mean_list))\n",
    "    \n",
    "    inter_variance_dict[method] = mean_per_bootstrap\n",
    "\n",
    "    #outlier indices - INTER\n",
    "    \n",
    "    q1 = np.percentile(intra_variance_dict[method], 25, method='midpoint')\n",
    "    q3 = np.percentile(intra_variance_dict[method], 75, method='midpoint')\n",
    "    iqr = q3 - q1\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper_array = np.where(inter_variance_dict[method] >= upper)[0]\n",
    "    lower_array = np.where(inter_variance_dict[method] <= lower)[0]\n",
    "    inter_upper_outlier_dict[method] = upper_array\n",
    "    inter_lower_outlier_dict[method] = lower_array\n",
    "\n",
    "#removing outliers - inter\n",
    "all_inter_indices = []\n",
    "for array in inter_upper_outlier_dict.values():\n",
    "    for i in range(len(array)):\n",
    "        if array[i] not in all_inter_indices:\n",
    "            all_inter_indices.append(array[i])\n",
    "\n",
    "for array in inter_lower_outlier_dict.values():\n",
    "    for i in range(len(array)):\n",
    "        if array[i] not in all_inter_indices:\n",
    "            all_inter_indices.append(array[i])\n",
    "\n",
    "for method in methods:\n",
    "    outlier_removed = []\n",
    "    for i in range(0,112):\n",
    "        if i not in all_inter_indices:\n",
    "            outlier_removed.append(inter_variance_dict[method][i])\n",
    "    inter_variance_dict[method] = outlier_removed\n",
    "\n",
    "#removing outliers - intra\n",
    "all_intra_indices = []\n",
    "for array in intra_upper_outlier_dict.values():\n",
    "    for i in range(len(array)):\n",
    "        if array[i] not in all_intra_indices:\n",
    "            all_intra_indices.append(array[i])\n",
    "\n",
    "for array in intra_lower_outlier_dict.values():\n",
    "    for i in range(len(array)):\n",
    "        if array[i] not in all_intra_indices:\n",
    "            all_intra_indices.append(array[i])\n",
    "\n",
    "for method in methods:\n",
    "    outlier_removed = []\n",
    "    for i in range(0,112):\n",
    "        if i not in all_intra_indices:\n",
    "            outlier_removed.append(intra_variance_dict[method][i])\n",
    "    intra_variance_dict[method] = outlier_removed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e7ddff-c040-48d8-9a60-db9a7a357cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0ccd4b0f-af2e-4eef-94d4-64cb841607d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPARE BETWEEN INTER- AND INTRA- VARIANCE FOR EACH METHOD\n",
    "p_vals = {}\n",
    "eff_size = {}\n",
    "for method in methods:\n",
    "    p_val = stats.ranksums(inter_variance_dict[method], intra_variance_dict[method])[1]\n",
    "    \n",
    "    n1 = len(inter_variance_dict[method])\n",
    "    n2 = len(intra_variance_dict[method])\n",
    "    sd1 = np.std(inter_variance_dict[method])\n",
    "    sd2 = np.std(intra_variance_dict[method])\n",
    "\n",
    "    mean1 = np.mean(inter_variance_dict[method])\n",
    "    mean2 = np.mean(intra_variance_dict[method])\n",
    "\n",
    "    pooled_sd = np.sqrt((((n1-1)*(sd1**2))+((n2-1)*(sd2**2)))/(n1+n2-2))\n",
    "\n",
    "    cohens_d = (mean1 - mean2) / pooled_sd\n",
    "\n",
    "    p_vals[method] = p_val\n",
    "    eff_size[method] = cohens_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "86690cd0-51c3-4ca0-bb10-f4c853499492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coh': 0.40775422899306024,\n",
       " 'ciplv': 0.02373141720130226,\n",
       " 'imcoh': 0.32843580646921433,\n",
       " 'wpli2': 0.03136463420300379}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c648d1-1d4c-4c81-8aa9-ab955a7a07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CHECK FOR NORMALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983c0e77-b759-4ef9-946b-3d143a76e849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coh ShapiroResult(statistic=0.9846452474594116, pvalue=0.548849880695343)\n",
      "ciplv ShapiroResult(statistic=0.9871822595596313, pvalue=0.6968898773193359)\n",
      "imcoh ShapiroResult(statistic=0.9774569869041443, pvalue=0.23813951015472412)\n",
      "wpli2 ShapiroResult(statistic=0.917051374912262, pvalue=0.0001960165536729619)\n"
     ]
    }
   ],
   "source": [
    "#normal distribution - INTRA\n",
    "for method in methods:\n",
    "    print(method, stats.shapiro(intra_variance_dict[method]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c3a2b91-732c-4667-8571-99fd788a5bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coh ShapiroResult(statistic=0.9920978546142578, pvalue=0.9327622652053833)\n",
      "ciplv ShapiroResult(statistic=0.9825155735015869, pvalue=0.4073140323162079)\n",
      "imcoh ShapiroResult(statistic=0.9905188083648682, pvalue=0.8642438054084778)\n",
      "wpli2 ShapiroResult(statistic=0.9734638929367065, pvalue=0.12633875012397766)\n"
     ]
    }
   ],
   "source": [
    "#normal distribution - INTER\n",
    "for method in methods:\n",
    "    print(method, stats.shapiro(inter_variance_dict[method]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf937a39-1e5c-4592-a61c-4f17dbcaf6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeveneResult(statistic=99.80369507414835, pvalue=2.58649314575522e-44)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Homogeneity of variance testing\n",
    "print(stats.levene(inter_variance_dict['coh'], inter_variance_dict['ciplv'], inter_variance_dict['wpli2'], inter_variance_dict['imcoh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed6c22-0ab1-4412-bba1-073aa3515d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPARE VARIANCES AMONG METHODS\n",
    "#BOOTSTRAP T STATISTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee405ee7-fb7c-4c2c-9c0e-383accdd490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_pairs = [('generalized_partial_directed_coherence','direct_directed_transfer_function'), \n",
    "                    ('generalized_partial_directed_coherence','pairwise_spectral_granger_prediction'), \n",
    "                    ('direct_directed_transfer_function','pairwise_spectral_granger_prediction')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16cb3ce0-ac82-4c89-92ed-2a9691679a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_vals_overall = []\n",
    "\n",
    "for variance_dict in [inter_variance_dict, intra_variance_dict]:\n",
    "\n",
    "    p_val_dict = {}\n",
    "\n",
    "    for pair in comparison_pairs:\n",
    "        method1 = pair[0]\n",
    "        method2 = pair[1]\n",
    "    \n",
    "        sample_size1 = len(variance_dict[method1])\n",
    "        sample_size2 = len(variance_dict[method2])\n",
    "        total_sample_size = sample_size1 + sample_size2\n",
    "    \n",
    "        mean1 = np.mean(variance_dict[method1])\n",
    "        mean2 = np.mean(variance_dict[method2])\n",
    "        \n",
    "        sd1 = np.std(variance_dict[method1])\n",
    "        sd2 = np.std(variance_dict[method2])\n",
    "        \n",
    "        n1 = len(variance_dict[method1])\n",
    "        n2 = len(variance_dict[method2])\n",
    "        \n",
    "        pooled_sd = np.sqrt(((n1-1)*(sd1**2) + (n2-1)*(sd2**2))/(n1 + n2 - 2))\n",
    "        \n",
    "        t_orig = (mean1 - mean2)/(pooled_sd * np.sqrt((1/n1) + (1/n2)))\n",
    "    \n",
    "        pooled_sample = variance_dict[method1] + variance_dict[method2]\n",
    "    \n",
    "        bootstrap_sample1 = []\n",
    "        bootstrap_sample2 = []\n",
    "        \n",
    "        for i in range(1000):\n",
    "            sample1 = []\n",
    "            sample2 = []\n",
    "            index1 = np.random.choice(range(0,total_sample_size),sample_size1)\n",
    "            index2 = np.random.choice(range(0,total_sample_size),sample_size2)\n",
    "            sample1 = np.array(pooled_sample)[index1]\n",
    "            sample2 = np.array(pooled_sample)[index2]\n",
    "            bootstrap_sample1.append(sample1)\n",
    "            bootstrap_sample2.append(sample2)\n",
    "\n",
    "        bootstrap_t_stats = []\n",
    "        for i in range(1000):\n",
    "            mean1 = np.mean(bootstrap_sample1[i])\n",
    "            mean2 = np.mean(bootstrap_sample2[i])\n",
    "            \n",
    "            sd1 = np.std(bootstrap_sample1[i])\n",
    "            sd2 = np.std(bootstrap_sample2[i])\n",
    "            \n",
    "            n1 = len(bootstrap_sample1[i])\n",
    "            n2 = len(bootstrap_sample2[i])\n",
    "            \n",
    "            pooled_sd = np.sqrt(((n1-1)*(sd1**2) + (n2-1)*(sd2**2))/(n1 + n2 - 2))\n",
    "            \n",
    "            t = (mean1 - mean2)/(pooled_sd * np.sqrt((1/n1) + (1/n2)))\n",
    "        \n",
    "            bootstrap_t_stats.append(t)\n",
    "        \n",
    "        count = 0\n",
    "        for t in bootstrap_t_stats:\n",
    "            if t > t_orig:\n",
    "                count += 1\n",
    "        \n",
    "        p_val = count/1000\n",
    "        \n",
    "        p_val_dict[pair] = p_val\n",
    "        \n",
    "    p_vals_overall.append(p_val_dict)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c75d5ee9-bdfe-4d71-bc6e-dce2ece0e47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{('coh', 'ciplv'): 0.0,\n",
       "  ('coh', 'imcoh'): 0.573,\n",
       "  ('coh', 'wpli2'): 1.0,\n",
       "  ('ciplv', 'imcoh'): 0.59,\n",
       "  ('ciplv', 'wpli2'): 1.0,\n",
       "  ('imcoh', 'wpli2'): 0.904},\n",
       " {('coh', 'ciplv'): 0.049,\n",
       "  ('coh', 'imcoh'): 0.224,\n",
       "  ('coh', 'wpli2'): 1.0,\n",
       "  ('ciplv', 'imcoh'): 0.218,\n",
       "  ('ciplv', 'wpli2'): 1.0,\n",
       "  ('imcoh', 'wpli2'): 0.964}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p_vals_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97ac55-3c2e-4bcd-9bf0-0581afa83d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
